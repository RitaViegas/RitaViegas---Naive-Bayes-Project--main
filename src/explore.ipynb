{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS (Classification Problem): \n",
    "\n",
    "## Google Play Store Reviews using NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 1: PROBLEM STATEMENT & DATA COLLECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1.1 PROBLEM STATEMENT***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal** -  automatically classify Google Play Store reviews as positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1.2 DATA COLLECTION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package_name</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.facebook.katana</td>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          package_name                                             review  \\\n",
       "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
       "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
       "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
       "3  com.facebook.katana   the new features suck for those of us who don...   \n",
       "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
       "\n",
       "   polarity  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns=None\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/raw/playstore_reviews_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 2: EXPLORATION & DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****2.1.1 Understanding the features****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the above questions and develop a predictive model, we collected data on the following variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `package_name` - Name of the mobile application (categorical)\n",
    "* `review` - Comment about the mobile application (categorical)\n",
    "* `polarity` - Class variable (0 or 1), being 0 a negative comment and 1, positive (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "(891, 3)\n"
     ]
    }
   ],
   "source": [
    "# Obtaining Dataset dimensions:\n",
    "print(\"Dataset dimensions:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset informations:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   package_name  891 non-null    object\n",
      " 1   review        891 non-null    object\n",
      " 2   polarity      891 non-null    int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 21.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Obtaining Dataset informations:\n",
    "print(\"Dataset informations:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types present in the dataset: [dtype('O') dtype('int64')]\n",
      "Number of categorical variables: 2\n",
      "Categorical variables: ['package_name', 'review']\n",
      "\n",
      "\n",
      "Number of numerical variables: 1\n",
      "Numerical variables: ['polarity']\n"
     ]
    }
   ],
   "source": [
    "# Analyze the types of information we have\n",
    "print(\"Data types present in the dataset:\", df.dtypes.unique())\n",
    "\n",
    "# Identify numerical and categorical variables\n",
    "numerical_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "categorical_vars = df.select_dtypes(include=['O']).columns\n",
    "\n",
    "# Count the number of numerical and categorical variables\n",
    "num_numerical_vars = len(numerical_vars)\n",
    "num_categorical_vars = len(categorical_vars)\n",
    "\n",
    "print(f\"Number of categorical variables: {num_categorical_vars}\")\n",
    "print(\"Categorical variables:\", list(categorical_vars))\n",
    "print('\\n')\n",
    "print(f\"Number of numerical variables: {num_numerical_vars}\")\n",
    "print(\"Numerical variables:\", list(numerical_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statements\n",
    "\n",
    "* This DataFame is composed by 891 rows and 3 columns (variables).\n",
    "* The data has:\n",
    "    * 2 categorical variables\n",
    "    * 1 numerical variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2.2.1 ELIMINATE DUPLICATES***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I will eliminate duplicates, which is essential to ensure data integrity. Duplicates can distort analyses, introduce bias, and affect model accuracy. This step helps keep the dataset clean by representing each input uniquely and reliably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "No duplicate rows found.\n"
     ]
    }
   ],
   "source": [
    "# Display initial row count\n",
    "initial_row_count = df.shape[0]\n",
    "\n",
    "# Check and remove duplicates\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
    "\n",
    "if num_duplicates > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"Duplicate rows have been removed. Row count reduced from {initial_row_count} to {df.shape[0]}.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* there are no duplicates ​​in this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2.2.2 ELIMINATE IRRELEVANT INFORMATION***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  polarity\n",
       "0   privacy at least put some option appear offli...         0\n",
       "1   messenger issues ever since the last update, ...         0\n",
       "2   profile any time my wife or anybody has more ...         0\n",
       "3   the new features suck for those of us who don...         0\n",
       "4   forced reload on uploading pic on replying co...         0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"package_name\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***2.2.3 DATA PROCESSING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>privacy at least put some option appear offlin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>messenger issues ever since the last update, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>profile any time my wife or anybody has more t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the new features suck for those of us who don'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forced reload on uploading pic on replying com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  polarity\n",
       "0  privacy at least put some option appear offlin...         0\n",
       "1  messenger issues ever since the last update, i...         0\n",
       "2  profile any time my wife or anybody has more t...         0\n",
       "3  the new features suck for those of us who don'...         0\n",
       "4  forced reload on uploading pic on replying com...         0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"] = df[\"review\"].str.strip().str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STEP 3 SPLIT TRAIN & TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"review\"]\n",
    "y = df[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3.1 Transform the text into a word count matrix***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_model = CountVectorizer(stop_words=\"english\")\n",
    "X_train = vec_model.fit_transform(X_train).toarray()\n",
    "X_test = vec_model.transform(X_test).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MACHINE LEARNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **NAIVE BAYES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       126\n",
      "           1       0.73      0.60      0.66        53\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.79      0.75      0.77       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "MultinomialNB accuracy: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "model_MultinominalNB = MultinomialNB()\n",
    "model_MultinominalNB.fit(X_train, y_train)\n",
    "y_pred_MultinominalNB = model_MultinominalNB.predict(X_test)\n",
    "\n",
    "print(\"MultinomialNB Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_MultinominalNB))\n",
    "\n",
    "MultinominalNB_accuracy = accuracy_score(y_test, y_pred_MultinominalNB)\n",
    "print(f\"MultinomialNB accuracy:\", (MultinominalNB_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       126\n",
      "           1       0.69      0.62      0.65        53\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.77      0.75      0.76       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "GaussianNB accuracy: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "model_Gaussian = GaussianNB()\n",
    "model_Gaussian.fit(X_train, y_train)\n",
    "y_pred_Gaussian = model_Gaussian.predict(X_test)\n",
    "\n",
    "print(\"GaussianNB Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_Gaussian))\n",
    "\n",
    "GaussianNB_accuracy = accuracy_score(y_test, y_pred_Gaussian)\n",
    "print(f\"GaussianNB accuracy:\", GaussianNB_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       126\n",
      "           1       0.70      0.40      0.51        53\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.74      0.66      0.68       179\n",
      "weighted avg       0.76      0.77      0.75       179\n",
      "\n",
      "BernoulliNB accuracy: 0.770949720670391\n"
     ]
    }
   ],
   "source": [
    "model_Bernoulli = BernoulliNB()\n",
    "model_Bernoulli.fit(X_train, y_train)\n",
    "y_pred_Bernoulli = model_Bernoulli.predict(X_test)\n",
    "\n",
    "print(\"BernoulliNB Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_Bernoulli))\n",
    "\n",
    "BernoulliNB_accuracy = accuracy_score(y_test, y_pred_Bernoulli)\n",
    "print(f\"BernoulliNB accuracy:\", BernoulliNB_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statements\n",
    "* Based on the metrics results, the MultinomialNB implementation achieved the best accuracy (81.56%), followed by GaussianNB (80.45%) and BernoulliNB (77.09%).\n",
    "* F1-Score Weighted (MultinomialNB): 0.81, indicating a good balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION\n",
    "I chose MultinomialNB as the best Naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### **Optimizing MultinomialNB with RANDOM FOREST**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### using Default hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85       126\n",
      "           1       0.64      0.74      0.68        53\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.76      0.78      0.77       179\n",
      "weighted avg       0.81      0.80      0.80       179\n",
      "\n",
      "Random Forest accuracy: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "Random_Forest_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest accuracy:\", Random_Forest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adjusting hyperparameters to improve Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model with tuned hyperparameters\n",
    "rf_model_tuned = RandomForestClassifier(\n",
    "    n_estimators=200,  \n",
    "    max_depth=10,  \n",
    "    min_samples_split=5,  \n",
    "    min_samples_leaf=2,  \n",
    "    max_features='sqrt', \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "\n",
    "rf_model_tuned.fit(X_train, y_train)\n",
    "y_pred_rf_tuned = rf_model_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report (Adjusted):\")\n",
    "print(classification_report(y_test, y_pred_rf_tuned))\n",
    "\n",
    "rf_tuned_accuracy = accuracy_score(y_test, y_pred_rf_tuned)\n",
    "print(f\"Random Forest (Adjusted) accuracy: {rf_tuned_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 82, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 8, 'n_estimators': 102}\n",
      "Improved accuracy in cross-validation: 0.7850819652755616\n",
      "\n",
      "Random Forest Classification Report (Optimized):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       126\n",
      "           1       0.74      0.58      0.65        53\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.79      0.75      0.76       179\n",
      "weighted avg       0.81      0.82      0.81       179\n",
      "\n",
      "Random Forest (Optimized) accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": randint(50, 500), \n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_depth\": randint(3, 100),  \n",
    "    \"min_samples_split\": randint(2, 10),  \n",
    "    \"min_samples_leaf\": randint(1, 10),  \n",
    "    \"max_features\": ['sqrt', 'log2', None]  \n",
    "}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Configurar o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=params,\n",
    "    n_iter=25, \n",
    "    cv=3,  \n",
    "    scoring=\"accuracy\",  \n",
    "    random_state=42,\n",
    "    verbose=1,  \n",
    "    n_jobs=2 \n",
    ")\n",
    "\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "print(\"Improved accuracy in cross-validation:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "best_rf_model = random_search.best_estimator_\n",
    "y_pred_rf_best = best_rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report (Optimized):\")\n",
    "print(classification_report(y_test, y_pred_rf_best))\n",
    "\n",
    "best_rf_accuracy = accuracy_score(y_test, y_pred_rf_best)\n",
    "print(f\"Random Forest (Optimized) accuracy: {best_rf_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statement:\n",
    "After optimization, Random Forest achieved similar results to MultinomialNB, being equally viable as a final model.\n",
    "However, I choose to keep MultinomialNB model, due to its simplicity and efficiency in the current sentiment analysis scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('model_MultinominalNB_42.sav', 'wb') as file:\n",
    "    pickle.dump(model_MultinominalNB, file)\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
